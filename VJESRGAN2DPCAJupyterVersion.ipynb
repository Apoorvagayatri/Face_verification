{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /Users/apoorvagayatrik/miniforge3/envs/tf_env/lib/python3.10/site-packages (0.18.1)\n",
      "Requirement already satisfied: numpy in /Users/apoorvagayatrik/miniforge3/envs/tf_env/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch in /Users/apoorvagayatrik/miniforge3/envs/tf_env/lib/python3.10/site-packages (from torchvision) (2.3.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/apoorvagayatrik/miniforge3/envs/tf_env/lib/python3.10/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: filelock in /Users/apoorvagayatrik/miniforge3/envs/tf_env/lib/python3.10/site-packages (from torch->torchvision) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/apoorvagayatrik/miniforge3/envs/tf_env/lib/python3.10/site-packages (from torch->torchvision) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/apoorvagayatrik/miniforge3/envs/tf_env/lib/python3.10/site-packages (from torch->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/apoorvagayatrik/miniforge3/envs/tf_env/lib/python3.10/site-packages (from torch->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/apoorvagayatrik/miniforge3/envs/tf_env/lib/python3.10/site-packages (from torch->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/apoorvagayatrik/miniforge3/envs/tf_env/lib/python3.10/site-packages (from torch->torchvision) (2024.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/apoorvagayatrik/miniforge3/envs/tf_env/lib/python3.10/site-packages (from jinja2->torch->torchvision) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/apoorvagayatrik/miniforge3/envs/tf_env/lib/python3.10/site-packages (from sympy->torch->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "aKizwQKB0s65"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import zipfile\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_dir='/Users/apoorvagayatrik/PerspectAIProj/dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "C1pKA_be7Uc2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "os.chdir('/Users/apoorvagayatrik/PerspectAIProj/ESRGAN')\n",
    "import RRDBNet_arch as arch\n",
    "\n",
    "# Define the apply_esrgan function\n",
    "def apply_esrgan(img, model, device):\n",
    "    img = img * 1.0 / 255\n",
    "    img = torch.from_numpy(np.transpose(img[:, :, [2, 1, 0]], (2, 0, 1))).float()\n",
    "    img_LR = img.unsqueeze(0)\n",
    "    img_LR = img_LR.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(img_LR).data.squeeze().float().cpu().clamp_(0, 1).numpy()\n",
    "    output = np.transpose(output[[2, 1, 0], :, :], (1, 2, 0))\n",
    "    output = (output * 255.0).round().astype(np.uint8)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "YDy73TbyM9sD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 16697987\n",
      "Model size: 63.88340950012207 MB\n"
     ]
    }
   ],
   "source": [
    "# Load the ESRGAN model\n",
    "model_path = '/Users/apoorvagayatrik/PerspectAIProj/ESRGAN/models/RRDB_ESRGAN_x4.pth'\n",
    "device = torch.device('cpu')  # if you want to run on CPU, change 'cuda' -> 'cpu'\n",
    "\n",
    "model = arch.RRDBNet(3, 3, 64, 23, gc=32)\n",
    "model.load_state_dict(torch.load(model_path), strict=True)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Example for a generic model\n",
    "total_params = count_parameters(model)\n",
    "print(f'Total number of parameters: {total_params}')\n",
    "\n",
    "def get_model_size(model, filepath):\n",
    "    torch.save(model.state_dict(), filepath)  # For PyTorch, or appropriate save function for other frameworks\n",
    "    return os.path.getsize(filepath)\n",
    "\n",
    "model_size = get_model_size(model, 'model.pth')\n",
    "print(f'Model size: {model_size / (1024**2)} MB')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zh1EAMHD7Z-G"
   },
   "outputs": [],
   "source": [
    "def detect_faces(image):\n",
    "\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-zQVECFV7zpr"
   },
   "outputs": [],
   "source": [
    "datasets=['train_ds','val_ds','test_ds']\n",
    "\n",
    "train_preprocessed=[]\n",
    "val_preprocessed=[]\n",
    "test_preprocessed=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FQhgGqjF6atq",
    "outputId": "842b3786-dd12-44e0-914b-fb528b4bd736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /Users/apoorvagayatrik/miniforge3/lib/python3.10/site-packages (4.66.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48o_7wxV8SAO",
    "outputId": "77f42fa8-201b-4f3c-8a62-b5ccb235244d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test_ds: 100%|████████████████| 35/35 [5:45:31<00:00, 592.33s/folder]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loading and enhancement completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming detect_faces and apply_esrgan functions are already defined\n",
    "\n",
    "datasets = ['train_ds', 'val_ds', 'test_ds']\n",
    "extract_dir = '/Users/apoorvagayatrik/PerspectAIProj/dataset'  # Adjust this to your actual extract directory\n",
    "output_dir = '/Users/apoorvagayatrik/PerspectAIProj/processed_images'  # Directory to save processed images\n",
    "\n",
    "# Initialize lists for storing preprocessed images\n",
    "train_preprocessed = []\n",
    "val_preprocessed = []\n",
    "test_preprocessed = []\n",
    "\n",
    "train_labels = []\n",
    "val_labels = []\n",
    "test_labels = []\n",
    "\n",
    "def load_images_and_labels(dataset):\n",
    "    images = []\n",
    "    labels = []\n",
    "    dataset_path = os.path.join(extract_dir, dataset)\n",
    "    people_folders = [f for f in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, f))]\n",
    "\n",
    "    progress_bar = tqdm(total=len(people_folders), desc=f'Processing {dataset}', unit='folder')\n",
    "\n",
    "    for person_folder in people_folders:\n",
    "        person_path = os.path.join(dataset_path, person_folder)\n",
    "        image_files = [os.path.join(person_path, f) for f in os.listdir(person_path) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "        label = person_folder\n",
    "        for image_path in image_files:\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "            faces = detect_faces(image)\n",
    "\n",
    "            for (x, y, w, h) in faces:\n",
    "                # Extract the face ROI\n",
    "                face_roi = image[y:y+h, x:x+w]\n",
    "                # Apply ESRGAN to the face ROI\n",
    "                enhanced_face = apply_esrgan(face_roi, model, device)\n",
    "\n",
    "                # Convert to grayscale\n",
    "                gray_face = cv2.cvtColor(enhanced_face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Resize the face to the target size\n",
    "                target_size = (64, 64)\n",
    "                resized_face = cv2.resize(gray_face, target_size)\n",
    "\n",
    "                # Save processed image\n",
    "                filename = os.path.basename(image_path)\n",
    "                output_path = os.path.join(output_dir, dataset, person_folder, filename)\n",
    "                os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "                cv2.imwrite(output_path, resized_face)\n",
    "\n",
    "                images.append(resized_face)\n",
    "                labels.append(label)\n",
    "        \n",
    "        progress_bar.update(1)\n",
    "\n",
    "    progress_bar.close()\n",
    "    return images, labels\n",
    "\n",
    "# Call the function to load and process images\n",
    "train_preprocessed, train_labels = load_images_and_labels('train_ds')\n",
    "val_preprocessed, val_labels = load_images_and_labels('val_ds')\n",
    "test_preprocessed, test_labels = load_images_and_labels('test_ds')\n",
    "\n",
    "print(\"Image loading and enhancement completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DOimtxtq9-NE",
    "outputId": "2a15293e-93ee-45a6-d2fd-18fa86ccf0ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. Running on CPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA (GPU acceleration) is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "if cuda_available:\n",
    "    # Get the CUDA device count\n",
    "    cuda_device_count = torch.cuda.device_count()\n",
    "    print('CUDA is available with {cuda_device_count} CUDA device(s)!')\n",
    "else:\n",
    "    print('CUDA is not available. Running on CPU.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_labels_from_directory(base_dir, target_size=(64, 64)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(base_dir):\n",
    "        label_dir = os.path.join(base_dir, label)\n",
    "        if os.path.isdir(label_dir):\n",
    "            for filename in os.listdir(label_dir):\n",
    "                if filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "                    img_path = os.path.join(label_dir, filename)\n",
    "                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    if img is not None:\n",
    "                        resized_img = cv2.resize(img, target_size)\n",
    "                        images.append(resized_img)\n",
    "                        labels.append(label)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = load_images_and_labels_from_directory('/Users/apoorvagayatrik/PerspectAIProj/processed_images/train_ds')\n",
    "val_images, val_labels = load_images_and_labels_from_directory('/Users/apoorvagayatrik/PerspectAIProj/processed_images/val_ds')\n",
    "test_images, test_labels = load_images_and_labels_from_directory('/Users/apoorvagayatrik/PerspectAIProj/processed_images/test_ds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "id": "we82aCcePfzc",
    "outputId": "88678efd-67d1-4733-bfa0-b764cb4648b7"
   },
   "outputs": [],
   "source": [
    "def compute_covmatrix(images):\n",
    "    num_images = len(images)\n",
    "    flattened_images = np.array([img.flatten() for img in images])\n",
    "    mean_image = np.mean(flattened_images, axis=0)\n",
    "    cov_matrix = np.cov(flattened_images, rowvar=False)\n",
    "    return cov_matrix\n",
    "\n",
    "\n",
    "\n",
    "train_cov_matrix = compute_covmatrix(train_images)\n",
    "val_cov_matrix = compute_covmatrix(val_images)\n",
    "test_cov_matrix = compute_covmatrix(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "VUlfjnnFQnmV",
    "outputId": "3af9d804-9745-4948-bfe5-c548080db27d"
   },
   "outputs": [],
   "source": [
    "def extract_principal_components(cov_matrix,num_components):\n",
    "    eig_vals,eig_vecs=np.linalg.eigh(cov_matrix)\n",
    "\n",
    "    sorted_indices=np.argsort(eig_vals)[::-1]\n",
    "    sorted_eig_vals=eig_vals[sorted_indices]\n",
    "    sorted_eig_vecs=eig_vecs[:,sorted_indices]\n",
    "  \n",
    "\n",
    "    principal_components=sorted_eig_vecs[:,:num_components]\n",
    "\n",
    "    return principal_components\n",
    "\n",
    "\n",
    "num_components = 50\n",
    "\n",
    "train_principal_components = extract_principal_components(train_cov_matrix, num_components)\n",
    "val_principal_components = extract_principal_components(val_cov_matrix, num_components)\n",
    "test_principal_components = extract_principal_components(test_cov_matrix, num_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "Ykop7GzQRqiN",
    "outputId": "72fbc6f7-706f-44a2-e064-a7e05e1fff47"
   },
   "outputs": [],
   "source": [
    "def project_images(images,principal_components):\n",
    "    num_images = len(images)\n",
    "    flattened_images = images.reshape(num_images, -1)  # Flatten each image into a vector\n",
    "    projected_images = np.dot(flattened_images, principal_components)\n",
    "\n",
    "    return projected_images\n",
    "\n",
    "train_projected = project_images(train_images, train_principal_components)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "id": "bgc8-FH9SB8J",
    "outputId": "5a71dfa4-1798-4ee8-8b72-1a7aa2be797a"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def train_classifier(projections,labels):\n",
    "    knn=KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(projections,labels)\n",
    "    return knn\n",
    "\n",
    "\n",
    "knn_classifier = train_classifier(train_projected, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/apoorvagayatrik/miniforge3/envs/tf_env/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.13.1-cp310-cp310-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m502.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.0-cp310-cp310-macosx_12_0_arm64.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.1-cp310-cp310-macosx_12_0_arm64.whl (30.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.3/30.3 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.0 scipy-1.13.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "6Cr7_nwBTDoD",
    "outputId": "d36096c2-c86a-4827-8a85-59dbd7d4eac0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.0\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       0.0\n",
      "          10       0.00      0.00      0.00       0.0\n",
      "        1003       0.00      0.00      0.00       0.0\n",
      "        1013       0.00      0.00      0.00       0.0\n",
      "        1017       0.00      0.00      0.00       0.0\n",
      "        1025       0.00      0.00      0.00       0.0\n",
      "        1027       0.00      0.00      0.00       0.0\n",
      "        1029       0.00      0.00      0.00       0.0\n",
      "        1032       0.00      0.00      0.00       0.0\n",
      "        1036       0.00      0.00      0.00       0.0\n",
      "        1038       0.00      0.00      0.00       0.0\n",
      "         104       0.00      0.00      0.00       0.0\n",
      "        1040       0.00      0.00      0.00       0.0\n",
      "        1042       0.00      0.00      0.00       0.0\n",
      "        1044       0.00      0.00      0.00       0.0\n",
      "        1045       0.00      0.00      0.00       0.0\n",
      "        1049       0.00      0.00      0.00       0.0\n",
      "        1051       0.00      0.00      0.00       0.0\n",
      "        1054       0.00      0.00      0.00       0.0\n",
      "        1055       0.00      0.00      0.00       0.0\n",
      "        1058       0.00      0.00      0.00       0.0\n",
      "        1070       0.00      0.00      0.00       0.0\n",
      "        1083       0.00      0.00      0.00       0.0\n",
      "        1087       0.00      0.00      0.00       0.0\n",
      "        1089       0.00      0.00      0.00       0.0\n",
      "        1092       0.00      0.00      0.00       0.0\n",
      "        1096       0.00      0.00      0.00       0.0\n",
      "        1099       0.00      0.00      0.00       0.0\n",
      "          11       0.00      0.00      0.00       0.0\n",
      "         110       0.00      0.00      0.00       0.0\n",
      "        1102       0.00      0.00      0.00       0.0\n",
      "        1103       0.00      0.00      0.00       0.0\n",
      "        1110       0.00      0.00      0.00       0.0\n",
      "        1114       0.00      0.00      0.00       0.0\n",
      "        1118       0.00      0.00      0.00       0.0\n",
      "        1119       0.00      0.00      0.00       0.0\n",
      "         113       0.00      0.00      0.00       0.0\n",
      "        1131       0.00      0.00      0.00       0.0\n",
      "        1133       0.00      0.00      0.00       0.0\n",
      "        1135       0.00      0.00      0.00       0.0\n",
      "        1140       0.00      0.00      0.00       0.0\n",
      "        1142       0.00      0.00      0.00       0.0\n",
      "        1146       0.00      0.00      0.00       0.0\n",
      "         115       0.00      0.00      0.00       0.0\n",
      "        1152       0.00      0.00      0.00       0.0\n",
      "        1158       0.00      0.00      0.00       0.0\n",
      "        1159       0.00      0.00      0.00       0.0\n",
      "        1160       0.00      0.00      0.00       0.0\n",
      "        1166       0.00      0.00      0.00       0.0\n",
      "        1174       0.00      0.00      0.00       0.0\n",
      "        1177       0.00      0.00      0.00       0.0\n",
      "        1182       0.00      0.00      0.00       0.0\n",
      "        1189       0.00      0.00      0.00       0.0\n",
      "        1194       0.00      0.00      0.00       0.0\n",
      "          12       0.00      0.00      0.00       0.0\n",
      "         120       0.00      0.00      0.00       0.0\n",
      "        1200       0.00      0.00      0.00       0.0\n",
      "        1201       0.00      0.00      0.00       0.0\n",
      "         121       0.00      0.00      0.00       0.0\n",
      "        1215       0.00      0.00      0.00       0.0\n",
      "        1217       0.00      0.00      0.00       0.0\n",
      "        1219       0.00      0.00      0.00       0.0\n",
      "         122       0.00      0.00      0.00       0.0\n",
      "        1229       0.00      0.00      0.00       0.0\n",
      "         123       0.00      0.00      0.00       0.0\n",
      "        1231       0.00      0.00      0.00       0.0\n",
      "        1233       0.00      0.00      0.00       0.0\n",
      "        1234       0.00      0.00      0.00       0.0\n",
      "        1236       0.00      0.00      0.00       0.0\n",
      "        1244       0.00      0.00      0.00       0.0\n",
      "        1248       0.00      0.00      0.00       0.0\n",
      "        1249       0.00      0.00      0.00       0.0\n",
      "        1257       0.00      0.00      0.00       0.0\n",
      "        1260       0.00      0.00      0.00       0.0\n",
      "        1264       0.00      0.00      0.00       0.0\n",
      "        1267       0.00      0.00      0.00       0.0\n",
      "        1268       0.00      0.00      0.00       0.0\n",
      "        1271       0.00      0.00      0.00       0.0\n",
      "        1280       0.00      0.00      0.00       0.0\n",
      "        1292       0.00      0.00      0.00       0.0\n",
      "        1293       0.00      0.00      0.00       0.0\n",
      "        1297       0.00      0.00      0.00       0.0\n",
      "        1310       0.00      0.00      0.00       0.0\n",
      "        1312       0.00      0.00      0.00       0.0\n",
      "        1317       0.00      0.00      0.00       0.0\n",
      "        1319       0.00      0.00      0.00       0.0\n",
      "        1320       0.00      0.00      0.00       0.0\n",
      "        1327       0.00      0.00      0.00       0.0\n",
      "        1330       0.00      0.00      0.00       0.0\n",
      "        1332       0.00      0.00      0.00       0.0\n",
      "        1338       0.00      0.00      0.00       0.0\n",
      "        1342       0.00      0.00      0.00       0.0\n",
      "        1347       0.00      0.00      0.00       0.0\n",
      "        1358       0.00      0.00      0.00       0.0\n",
      "         136       0.00      0.00      0.00       0.0\n",
      "        1360       0.00      0.00      0.00       0.0\n",
      "        1364       0.00      0.00      0.00       0.0\n",
      "        1369       0.00      0.00      0.00       0.0\n",
      "        1375       0.00      0.00      0.00       0.0\n",
      "        1384       0.00      0.00      0.00       0.0\n",
      "        1390       0.00      0.00      0.00       0.0\n",
      "        1391       0.00      0.00      0.00       0.0\n",
      "        1414       0.00      0.00      0.00       0.0\n",
      "        1419       0.00      0.00      0.00       0.0\n",
      "        1424       0.00      0.00      0.00       0.0\n",
      "        1431       0.00      0.00      0.00       0.0\n",
      "        1432       0.00      0.00      0.00       0.0\n",
      "        1434       0.00      0.00      0.00       0.0\n",
      "         144       0.00      0.00      0.00       0.0\n",
      "        1454       0.00      0.00      0.00       0.0\n",
      "        1459       0.00      0.00      0.00       0.0\n",
      "        1462       0.00      0.00      0.00       0.0\n",
      "        1465       0.00      0.00      0.00       0.0\n",
      "        1466       0.00      0.00      0.00       0.0\n",
      "        1470       0.00      0.00      0.00       0.0\n",
      "        1483       0.00      0.00      0.00       0.0\n",
      "        1484       0.00      0.00      0.00       0.0\n",
      "        1504       0.00      0.00      0.00       0.0\n",
      "        1505       0.00      0.00      0.00       0.0\n",
      "        1506       0.00      0.00      0.00       0.0\n",
      "        1512       0.00      0.00      0.00       0.0\n",
      "        1515       0.00      0.00      0.00       0.0\n",
      "        1519       0.00      0.00      0.00       0.0\n",
      "        1524       0.00      0.00      0.00       0.0\n",
      "        1526       0.00      0.00      0.00       0.0\n",
      "        1528       0.00      0.00      0.00       0.0\n",
      "        1530       0.00      0.00      0.00       0.0\n",
      "        1534       0.00      0.00      0.00       0.0\n",
      "        1535       0.00      0.00      0.00       0.0\n",
      "        1540       0.00      0.00      0.00       0.0\n",
      "        1547       0.00      0.00      0.00       0.0\n",
      "        1553       0.00      0.00      0.00       0.0\n",
      "        1556       0.00      0.00      0.00       0.0\n",
      "        1558       0.00      0.00      0.00       0.0\n",
      "        1595       0.00      0.00      0.00       0.0\n",
      "        1611       0.00      0.00      0.00       0.0\n",
      "        1619       0.00      0.00      0.00       0.0\n",
      "        1634       0.00      0.00      0.00       0.0\n",
      "        1642       0.00      0.00      0.00       0.0\n",
      "        1643       0.00      0.00      0.00       0.0\n",
      "         166       0.00      0.00      0.00       0.0\n",
      "        1664       0.00      0.00      0.00       0.0\n",
      "        1667       0.00      0.00      0.00       0.0\n",
      "        1668       0.00      0.00      0.00       0.0\n",
      "        1671       0.00      0.00      0.00       0.0\n",
      "        1676       0.00      0.00      0.00       0.0\n",
      "        1686       0.00      0.00      0.00       0.0\n",
      "        1689       0.00      0.00      0.00       0.0\n",
      "        1692       0.00      0.00      0.00       0.0\n",
      "         170       0.00      0.00      0.00       0.0\n",
      "        1703       0.00      0.00      0.00       0.0\n",
      "        1720       0.00      0.00      0.00       0.0\n",
      "         173       0.00      0.00      0.00       0.0\n",
      "        1730       0.00      0.00      0.00       0.0\n",
      "        1732       0.00      0.00      0.00       0.0\n",
      "        1741       0.00      0.00      0.00       0.0\n",
      "         184       0.00      0.00      0.00       0.0\n",
      "          19       0.00      0.00      0.00       0.0\n",
      "        1907       0.00      0.00      0.00      37.0\n",
      "        1908       0.00      0.00      0.00       3.0\n",
      "        1909       0.00      0.00      0.00      44.0\n",
      "        1910       0.00      0.00      0.00      36.0\n",
      "        1911       0.00      0.00      0.00      24.0\n",
      "        1912       0.00      0.00      0.00      91.0\n",
      "        1913       0.00      0.00      0.00      55.0\n",
      "        1914       0.00      0.00      0.00      60.0\n",
      "        1915       0.00      0.00      0.00     109.0\n",
      "        1916       0.00      0.00      0.00      69.0\n",
      "        1917       0.00      0.00      0.00     104.0\n",
      "        1918       0.00      0.00      0.00      49.0\n",
      "        1919       0.00      0.00      0.00       9.0\n",
      "        1920       0.00      0.00      0.00      86.0\n",
      "        1921       0.00      0.00      0.00      15.0\n",
      "        1922       0.00      0.00      0.00       7.0\n",
      "        1923       0.00      0.00      0.00      88.0\n",
      "        1924       0.00      0.00      0.00     106.0\n",
      "        1925       0.00      0.00      0.00     102.0\n",
      "        1926       0.00      0.00      0.00       4.0\n",
      "        1927       0.00      0.00      0.00     119.0\n",
      "        1929       0.00      0.00      0.00      94.0\n",
      "        1930       0.00      0.00      0.00      49.0\n",
      "        1931       0.00      0.00      0.00       1.0\n",
      "        1932       0.00      0.00      0.00     132.0\n",
      "        1933       0.00      0.00      0.00      33.0\n",
      "        1934       0.00      0.00      0.00      57.0\n",
      "        1935       0.00      0.00      0.00      36.0\n",
      "        1936       0.00      0.00      0.00      59.0\n",
      "        1937       0.00      0.00      0.00      10.0\n",
      "        1938       0.00      0.00      0.00      26.0\n",
      "        1939       0.00      0.00      0.00      93.0\n",
      "        1940       0.00      0.00      0.00       7.0\n",
      "        1941       0.00      0.00      0.00      27.0\n",
      "        1942       0.00      0.00      0.00      32.0\n",
      "        1943       0.00      0.00      0.00      75.0\n",
      "        1944       0.00      0.00      0.00       2.0\n",
      "        1945       0.00      0.00      0.00     110.0\n",
      "        1946       0.00      0.00      0.00     108.0\n",
      "        1947       0.00      0.00      0.00      87.0\n",
      "        1948       0.00      0.00      0.00      16.0\n",
      "        1949       0.00      0.00      0.00      32.0\n",
      "        1950       0.00      0.00      0.00       4.0\n",
      "        1951       0.00      0.00      0.00      38.0\n",
      "        1952       0.00      0.00      0.00      88.0\n",
      "        1953       0.00      0.00      0.00      11.0\n",
      "        1954       0.00      0.00      0.00      44.0\n",
      "        1955       0.00      0.00      0.00      28.0\n",
      "        1956       0.00      0.00      0.00      52.0\n",
      "        1957       0.00      0.00      0.00      12.0\n",
      "         199       0.00      0.00      0.00       0.0\n",
      "         202       0.00      0.00      0.00       0.0\n",
      "         206       0.00      0.00      0.00       0.0\n",
      "          21       0.00      0.00      0.00       0.0\n",
      "         213       0.00      0.00      0.00       0.0\n",
      "         215       0.00      0.00      0.00       0.0\n",
      "         225       0.00      0.00      0.00       0.0\n",
      "         232       0.00      0.00      0.00       0.0\n",
      "         237       0.00      0.00      0.00       0.0\n",
      "         247       0.00      0.00      0.00       0.0\n",
      "         254       0.00      0.00      0.00       0.0\n",
      "         257       0.00      0.00      0.00       0.0\n",
      "         262       0.00      0.00      0.00       0.0\n",
      "         265       0.00      0.00      0.00       0.0\n",
      "         267       0.00      0.00      0.00       0.0\n",
      "         275       0.00      0.00      0.00       0.0\n",
      "         280       0.00      0.00      0.00       0.0\n",
      "          29       0.00      0.00      0.00       0.0\n",
      "         295       0.00      0.00      0.00       0.0\n",
      "         304       0.00      0.00      0.00       0.0\n",
      "         314       0.00      0.00      0.00       0.0\n",
      "         326       0.00      0.00      0.00       0.0\n",
      "         327       0.00      0.00      0.00       0.0\n",
      "         330       0.00      0.00      0.00       0.0\n",
      "         336       0.00      0.00      0.00       0.0\n",
      "         337       0.00      0.00      0.00       0.0\n",
      "         340       0.00      0.00      0.00       0.0\n",
      "         342       0.00      0.00      0.00       0.0\n",
      "         343       0.00      0.00      0.00       0.0\n",
      "         346       0.00      0.00      0.00       0.0\n",
      "          35       0.00      0.00      0.00       0.0\n",
      "         350       0.00      0.00      0.00       0.0\n",
      "         353       0.00      0.00      0.00       0.0\n",
      "         384       0.00      0.00      0.00       0.0\n",
      "         385       0.00      0.00      0.00       0.0\n",
      "           4       0.00      0.00      0.00       0.0\n",
      "          40       0.00      0.00      0.00       0.0\n",
      "         401       0.00      0.00      0.00       0.0\n",
      "         415       0.00      0.00      0.00       0.0\n",
      "         422       0.00      0.00      0.00       0.0\n",
      "         431       0.00      0.00      0.00       0.0\n",
      "         447       0.00      0.00      0.00       0.0\n",
      "         468       0.00      0.00      0.00       0.0\n",
      "         470       0.00      0.00      0.00       0.0\n",
      "         474       0.00      0.00      0.00       0.0\n",
      "         479       0.00      0.00      0.00       0.0\n",
      "         492       0.00      0.00      0.00       0.0\n",
      "         497       0.00      0.00      0.00       0.0\n",
      "         507       0.00      0.00      0.00       0.0\n",
      "          52       0.00      0.00      0.00       0.0\n",
      "         520       0.00      0.00      0.00       0.0\n",
      "         525       0.00      0.00      0.00       0.0\n",
      "          53       0.00      0.00      0.00       0.0\n",
      "         560       0.00      0.00      0.00       0.0\n",
      "         563       0.00      0.00      0.00       0.0\n",
      "         564       0.00      0.00      0.00       0.0\n",
      "          57       0.00      0.00      0.00       0.0\n",
      "         572       0.00      0.00      0.00       0.0\n",
      "         579       0.00      0.00      0.00       0.0\n",
      "         588       0.00      0.00      0.00       0.0\n",
      "         594       0.00      0.00      0.00       0.0\n",
      "         597       0.00      0.00      0.00       0.0\n",
      "           6       0.00      0.00      0.00       0.0\n",
      "         605       0.00      0.00      0.00       0.0\n",
      "         607       0.00      0.00      0.00       0.0\n",
      "         616       0.00      0.00      0.00       0.0\n",
      "         621       0.00      0.00      0.00       0.0\n",
      "         626       0.00      0.00      0.00       0.0\n",
      "         627       0.00      0.00      0.00       0.0\n",
      "         632       0.00      0.00      0.00       0.0\n",
      "         636       0.00      0.00      0.00       0.0\n",
      "         645       0.00      0.00      0.00       0.0\n",
      "         652       0.00      0.00      0.00       0.0\n",
      "         654       0.00      0.00      0.00       0.0\n",
      "         659       0.00      0.00      0.00       0.0\n",
      "         664       0.00      0.00      0.00       0.0\n",
      "         668       0.00      0.00      0.00       0.0\n",
      "         675       0.00      0.00      0.00       0.0\n",
      "         678       0.00      0.00      0.00       0.0\n",
      "         679       0.00      0.00      0.00       0.0\n",
      "         683       0.00      0.00      0.00       0.0\n",
      "         688       0.00      0.00      0.00       0.0\n",
      "         697       0.00      0.00      0.00       0.0\n",
      "         705       0.00      0.00      0.00       0.0\n",
      "         713       0.00      0.00      0.00       0.0\n",
      "         715       0.00      0.00      0.00       0.0\n",
      "         716       0.00      0.00      0.00       0.0\n",
      "         717       0.00      0.00      0.00       0.0\n",
      "         732       0.00      0.00      0.00       0.0\n",
      "         733       0.00      0.00      0.00       0.0\n",
      "         752       0.00      0.00      0.00       0.0\n",
      "         753       0.00      0.00      0.00       0.0\n",
      "         763       0.00      0.00      0.00       0.0\n",
      "         766       0.00      0.00      0.00       0.0\n",
      "         775       0.00      0.00      0.00       0.0\n",
      "         783       0.00      0.00      0.00       0.0\n",
      "         785       0.00      0.00      0.00       0.0\n",
      "         796       0.00      0.00      0.00       0.0\n",
      "         797       0.00      0.00      0.00       0.0\n",
      "          80       0.00      0.00      0.00       0.0\n",
      "         802       0.00      0.00      0.00       0.0\n",
      "         812       0.00      0.00      0.00       0.0\n",
      "         815       0.00      0.00      0.00       0.0\n",
      "         821       0.00      0.00      0.00       0.0\n",
      "         824       0.00      0.00      0.00       0.0\n",
      "         829       0.00      0.00      0.00       0.0\n",
      "         830       0.00      0.00      0.00       0.0\n",
      "         844       0.00      0.00      0.00       0.0\n",
      "         849       0.00      0.00      0.00       0.0\n",
      "         850       0.00      0.00      0.00       0.0\n",
      "         855       0.00      0.00      0.00       0.0\n",
      "         863       0.00      0.00      0.00       0.0\n",
      "         877       0.00      0.00      0.00       0.0\n",
      "         881       0.00      0.00      0.00       0.0\n",
      "         887       0.00      0.00      0.00       0.0\n",
      "         915       0.00      0.00      0.00       0.0\n",
      "          92       0.00      0.00      0.00       0.0\n",
      "         920       0.00      0.00      0.00       0.0\n",
      "         923       0.00      0.00      0.00       0.0\n",
      "         926       0.00      0.00      0.00       0.0\n",
      "         930       0.00      0.00      0.00       0.0\n",
      "         931       0.00      0.00      0.00       0.0\n",
      "         953       0.00      0.00      0.00       0.0\n",
      "         954       0.00      0.00      0.00       0.0\n",
      "         956       0.00      0.00      0.00       0.0\n",
      "         959       0.00      0.00      0.00       0.0\n",
      "         964       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00    2580.0\n",
      "   macro avg       0.00      0.00      0.00    2580.0\n",
      "weighted avg       0.00      0.00      0.00    2580.0\n",
      "\n",
      "Test Accuracy: 0.0\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         122       0.00      0.00      0.00       0.0\n",
      "        1552       0.00      0.00      0.00       0.0\n",
      "        1755       0.00      0.00      0.00      30.0\n",
      "        1756       0.00      0.00      0.00      29.0\n",
      "        1757       0.00      0.00      0.00      30.0\n",
      "        1758       0.00      0.00      0.00      30.0\n",
      "        1759       0.00      0.00      0.00      11.0\n",
      "        1760       0.00      0.00      0.00      30.0\n",
      "        1761       0.00      0.00      0.00      30.0\n",
      "        1762       0.00      0.00      0.00      30.0\n",
      "        1763       0.00      0.00      0.00      20.0\n",
      "        1764       0.00      0.00      0.00      30.0\n",
      "        1765       0.00      0.00      0.00      30.0\n",
      "        1766       0.00      0.00      0.00      13.0\n",
      "        1768       0.00      0.00      0.00      28.0\n",
      "        1769       0.00      0.00      0.00      30.0\n",
      "        1770       0.00      0.00      0.00      30.0\n",
      "        1771       0.00      0.00      0.00      22.0\n",
      "        1772       0.00      0.00      0.00      30.0\n",
      "        1773       0.00      0.00      0.00      30.0\n",
      "        1774       0.00      0.00      0.00      30.0\n",
      "        1775       0.00      0.00      0.00      28.0\n",
      "        1776       0.00      0.00      0.00      30.0\n",
      "        1777       0.00      0.00      0.00      30.0\n",
      "        1778       0.00      0.00      0.00      28.0\n",
      "        1779       0.00      0.00      0.00      30.0\n",
      "        1780       0.00      0.00      0.00      30.0\n",
      "       1780_       0.00      0.00      0.00      30.0\n",
      "        1781       0.00      0.00      0.00      29.0\n",
      "        1782       0.00      0.00      0.00      30.0\n",
      "        1783       0.00      0.00      0.00       1.0\n",
      "        1784       0.00      0.00      0.00      29.0\n",
      "        1786       0.00      0.00      0.00      30.0\n",
      "        1787       0.00      0.00      0.00       1.0\n",
      "        1788       0.00      0.00      0.00      30.0\n",
      "        1789       0.00      0.00      0.00      30.0\n",
      "        1790       0.00      0.00      0.00      27.0\n",
      "        1791       0.00      0.00      0.00      15.0\n",
      "        1792       0.00      0.00      0.00      30.0\n",
      "        1793       0.00      0.00      0.00      30.0\n",
      "        1795       0.00      0.00      0.00      25.0\n",
      "        1796       0.00      0.00      0.00      30.0\n",
      "        1797       0.00      0.00      0.00      29.0\n",
      "        1798       0.00      0.00      0.00      30.0\n",
      "        1799       0.00      0.00      0.00      30.0\n",
      "        1800       0.00      0.00      0.00      30.0\n",
      "        1801       0.00      0.00      0.00      30.0\n",
      "        1802       0.00      0.00      0.00      20.0\n",
      "        1803       0.00      0.00      0.00      30.0\n",
      "        1804       0.00      0.00      0.00      30.0\n",
      "        1805       0.00      0.00      0.00      30.0\n",
      "        1806       0.00      0.00      0.00      30.0\n",
      "        1807       0.00      0.00      0.00      30.0\n",
      "        1808       0.00      0.00      0.00      18.0\n",
      "        1809       0.00      0.00      0.00      28.0\n",
      "        1810       0.00      0.00      0.00      30.0\n",
      "        1811       0.00      0.00      0.00      30.0\n",
      "        1812       0.00      0.00      0.00       4.0\n",
      "        1813       0.00      0.00      0.00      30.0\n",
      "        1814       0.00      0.00      0.00      30.0\n",
      "        1815       0.00      0.00      0.00      30.0\n",
      "        1816       0.00      0.00      0.00      18.0\n",
      "        1817       0.00      0.00      0.00      30.0\n",
      "        1818       0.00      0.00      0.00      30.0\n",
      "        1819       0.00      0.00      0.00      28.0\n",
      "        1820       0.00      0.00      0.00      30.0\n",
      "        1821       0.00      0.00      0.00      30.0\n",
      "        1822       0.00      0.00      0.00      30.0\n",
      "        1823       0.00      0.00      0.00      26.0\n",
      "        1824       0.00      0.00      0.00      28.0\n",
      "        1825       0.00      0.00      0.00      30.0\n",
      "        1826       0.00      0.00      0.00      30.0\n",
      "        1827       0.00      0.00      0.00      30.0\n",
      "        1828       0.00      0.00      0.00      30.0\n",
      "        1829       0.00      0.00      0.00      30.0\n",
      "        1830       0.00      0.00      0.00      30.0\n",
      "        1831       0.00      0.00      0.00      30.0\n",
      "        1832       0.00      0.00      0.00      30.0\n",
      "        1833       0.00      0.00      0.00      30.0\n",
      "        1834       0.00      0.00      0.00      27.0\n",
      "        1835       0.00      0.00      0.00      30.0\n",
      "        1836       0.00      0.00      0.00      30.0\n",
      "        1837       0.00      0.00      0.00      25.0\n",
      "        1838       0.00      0.00      0.00      30.0\n",
      "        1839       0.00      0.00      0.00      30.0\n",
      "        1840       0.00      0.00      0.00      15.0\n",
      "        1841       0.00      0.00      0.00      30.0\n",
      "        1842       0.00      0.00      0.00      30.0\n",
      "        1843       0.00      0.00      0.00      13.0\n",
      "        1844       0.00      0.00      0.00      30.0\n",
      "        1845       0.00      0.00      0.00      30.0\n",
      "        1846       0.00      0.00      0.00      29.0\n",
      "        1847       0.00      0.00      0.00      30.0\n",
      "        1848       0.00      0.00      0.00      30.0\n",
      "        1849       0.00      0.00      0.00      30.0\n",
      "        1850       0.00      0.00      0.00      30.0\n",
      "        1851       0.00      0.00      0.00      30.0\n",
      "        1852       0.00      0.00      0.00      30.0\n",
      "        1853       0.00      0.00      0.00      30.0\n",
      "        1854       0.00      0.00      0.00      28.0\n",
      "        1855       0.00      0.00      0.00      30.0\n",
      "        1856       0.00      0.00      0.00      30.0\n",
      "        1857       0.00      0.00      0.00      30.0\n",
      "        1858       0.00      0.00      0.00      30.0\n",
      "        1859       0.00      0.00      0.00      30.0\n",
      "        1860       0.00      0.00      0.00      30.0\n",
      "        1861       0.00      0.00      0.00      30.0\n",
      "        1862       0.00      0.00      0.00      30.0\n",
      "        1863       0.00      0.00      0.00      30.0\n",
      "        1864       0.00      0.00      0.00      30.0\n",
      "        1865       0.00      0.00      0.00      30.0\n",
      "        1866       0.00      0.00      0.00      30.0\n",
      "        1867       0.00      0.00      0.00      30.0\n",
      "        1869       0.00      0.00      0.00      28.0\n",
      "        1870       0.00      0.00      0.00      30.0\n",
      "        1871       0.00      0.00      0.00      22.0\n",
      "        1872       0.00      0.00      0.00      30.0\n",
      "        1873       0.00      0.00      0.00      30.0\n",
      "        1874       0.00      0.00      0.00      30.0\n",
      "        1875       0.00      0.00      0.00      30.0\n",
      "        1876       0.00      0.00      0.00      22.0\n",
      "        1877       0.00      0.00      0.00      30.0\n",
      "        1878       0.00      0.00      0.00      30.0\n",
      "        1879       0.00      0.00      0.00      30.0\n",
      "        1880       0.00      0.00      0.00      30.0\n",
      "        1881       0.00      0.00      0.00      30.0\n",
      "        1882       0.00      0.00      0.00      30.0\n",
      "        1883       0.00      0.00      0.00      27.0\n",
      "        1884       0.00      0.00      0.00      30.0\n",
      "        1886       0.00      0.00      0.00      18.0\n",
      "        1887       0.00      0.00      0.00      30.0\n",
      "        1888       0.00      0.00      0.00      28.0\n",
      "        1889       0.00      0.00      0.00      30.0\n",
      "        1890       0.00      0.00      0.00      29.0\n",
      "        1891       0.00      0.00      0.00      30.0\n",
      "        1892       0.00      0.00      0.00      30.0\n",
      "        1893       0.00      0.00      0.00      30.0\n",
      "        1894       0.00      0.00      0.00      30.0\n",
      "        1895       0.00      0.00      0.00      28.0\n",
      "        1896       0.00      0.00      0.00      30.0\n",
      "        1897       0.00      0.00      0.00      30.0\n",
      "        1898       0.00      0.00      0.00       6.0\n",
      "        1899       0.00      0.00      0.00      30.0\n",
      "        1900       0.00      0.00      0.00      30.0\n",
      "        1901       0.00      0.00      0.00      30.0\n",
      "        1903       0.00      0.00      0.00      26.0\n",
      "        1904       0.00      0.00      0.00      30.0\n",
      "        1905       0.00      0.00      0.00      30.0\n",
      "        1906       0.00      0.00      0.00      30.0\n",
      "         513       0.00      0.00      0.00       0.0\n",
      "         753       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00    4086.0\n",
      "   macro avg       0.00      0.00      0.00    4086.0\n",
      "weighted avg       0.00      0.00      0.00    4086.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apoorvagayatrik/miniforge3/envs/tf_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/apoorvagayatrik/miniforge3/envs/tf_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/apoorvagayatrik/miniforge3/envs/tf_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/apoorvagayatrik/miniforge3/envs/tf_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/apoorvagayatrik/miniforge3/envs/tf_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/apoorvagayatrik/miniforge3/envs/tf_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/apoorvagayatrik/miniforge3/envs/tf_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/apoorvagayatrik/miniforge3/envs/tf_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/apoorvagayatrik/miniforge3/envs/tf_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/apoorvagayatrik/miniforge3/envs/tf_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/apoorvagayatrik/miniforge3/envs/tf_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/apoorvagayatrik/miniforge3/envs/tf_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "def evaluate_classifier(knn_classifier, test_images, test_labels, principal_components):\n",
    "    num_images = len(test_images)\n",
    "    flattened_images = np.array([img.flatten() for img in test_images])\n",
    "    projected_images = np.dot(flattened_images, principal_components)\n",
    "    predictions = knn_classifier.predict(projected_images)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    report = classification_report(test_labels, predictions)\n",
    "    return accuracy, report\n",
    "\n",
    "# Evaluate classifier on validation and test datasets\n",
    "val_accuracy, val_report = evaluate_classifier(knn_classifier, val_images, val_labels, val_principal_components)\n",
    "test_accuracy, test_report = evaluate_classifier(knn_classifier, test_images, test_labels, test_principal_components)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "print(f\"Validation Report:\\n{val_report}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Report:\\n{test_report}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "mmDZ0A19a0_R"
   },
   "outputs": [],
   "source": [
    "def recognize_faces(classifier, images, principal_components):\n",
    "    num_images = len(images)\n",
    "    flattened_images = np.array([img.flatten() for img in images])\n",
    "    projected_images = np.dot(flattened_images, principal_components)\n",
    "    predictions = classifier.predict(projected_images)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# Perform face recognition on test set\n",
    "test_predictions = recognize_faces(knn_classifier, test_images, train_principal_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/Users/apoorvagayatrik/PerspectAIProj/ESRGAN/models/RRDB_ESRGAN_x4.pth'\n",
    "\n",
    "\n",
    "model_size = get_model_size(model, model_path)\n",
    "\n",
    "total_params = count_parameters(model)\n",
    "print('Total number of parameters: {total_params}')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
