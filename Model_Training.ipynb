{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8254a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score,precision_score\n",
    "\n",
    "\n",
    "train_folder='/Users/apoorvagayatrik/PerspectAIProj/processed_images/train_ds'\n",
    "test_folder='/Users/apoorvagayatrik/PerspectAIProj/processed_images/test_ds'\n",
    "val_folder='/Users/apoorvagayatrik/PerspectAIProj/processed_images/val_ds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "739e8fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for person_folder in os.listdir(folder):\n",
    "        person_path = os.path.join(folder, person_folder)\n",
    "        if not os.path.isdir(person_path):  # Skip non-directory files like .DS_Store\n",
    "            continue\n",
    "        for filename in os.listdir(person_path):\n",
    "            img_path = os.path.join(person_path, filename)\n",
    "            if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Read image as grayscale\n",
    "                if img is not None:\n",
    "                    images.append(img)  # Flatten image to 1D array\n",
    "                    labels.append(person_folder)  # Use folder name as label\n",
    "    return np.array(images), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e32afcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 17260 training images and 2580 validation images.\n"
     ]
    }
   ],
   "source": [
    "# Load images and labels from respective folders\n",
    "\n",
    "train_images, train_labels = load_images_from_folder(train_folder)\n",
    "val_images, val_labels = load_images_from_folder(val_folder)\n",
    "test_images, test_labels = load_images_from_folder(test_folder)\n",
    "\n",
    "print(f\"Loaded {len(train_images)} training images and {len(val_images)} validation images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48cc3736",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 17260/17260 [00:27<00:00, 625.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PCA model and transformed data.\n",
      "train_images_2dpca shape: (17260, 3200)\n",
      "val_images_2dpca shape: (2580, 3200)\n",
      "test_images_2dpca shape: (4086, 3200)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle    \n",
    "\n",
    "class TwoDPCA:\n",
    "    def __init__(self,num_components):\n",
    "        self.num_components=num_components\n",
    "        self.eigenvectors=None\n",
    "        \n",
    "    def fit(self,X):\n",
    "        mean_image=np.mean(X,axis=0)\n",
    "        \n",
    "        covariance_matrix=np.zeros((X.shape[1],X.shape[1]))\n",
    "        \n",
    "        for img in tqdm(X):\n",
    "            diff=img-mean_image\n",
    "            covariance_matrix+=np.dot(diff.T,diff)\n",
    "            \n",
    "            eigenvalues,eigenvectors=np.linalg.eigh(covariance_matrix)\n",
    "            \n",
    "            idx=np.argsort(-eigenvalues)\n",
    "            \n",
    "            self.eigenvectors=eigenvectors[:,idx[:self.num_components]]\n",
    "            \n",
    "            \n",
    "    def transform(self,X):\n",
    "        projected_images=[]\n",
    "        \n",
    "        for img in X:\n",
    "            projected_img=np.dot(img,self.eigenvectors)\n",
    "            projected_images.append(projected_img.flatten())\n",
    "            \n",
    "        return np.array(projected_images)\n",
    "    \n",
    "    \n",
    "num_components = 50\n",
    "two_d_pca = TwoDPCA(num_components)\n",
    "\n",
    "two_d_pca.fit(train_images)\n",
    "\n",
    "train_images_2dpca = two_d_pca.transform(train_images)\n",
    "val_images_2dpca = two_d_pca.transform(val_images)\n",
    "test_images_2dpca = two_d_pca.transform(test_images)\n",
    "\n",
    "with open('two_d_pca_model.pkl', 'wb') as f:\n",
    "        pickle.dump(two_d_pca, f)\n",
    "with open('transformed_data.pkl', 'wb') as f:\n",
    "        pickle.dump((train_images_2dpca, val_images_2dpca, test_images_2dpca), f)\n",
    "print(\"Saved PCA model and transformed data.\")\n",
    "\n",
    "print(f\"train_images_2dpca shape: {train_images_2dpca.shape}\")\n",
    "print(f\"val_images_2dpca shape: {val_images_2dpca.shape}\")\n",
    "print(f\"test_images_2dpca shape: {test_images_2dpca.shape}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76bc88b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1b3f790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9670542635658915\n",
      "Validation Precision: 0.431583981158723\n",
      "Test Accuracy: 0.9725893294175233\n",
      "Test Precision: 0.8084737360278212\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and train KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(train_images_2dpca, train_labels)\n",
    "\n",
    "\n",
    "\n",
    "# Predict on validation set\n",
    "val_predictions = knn.predict(val_images_2dpca)\n",
    "val_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "val_precision = precision_score(val_labels, val_predictions, average='macro',zero_division=1)\n",
    "\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "print(f\"Validation Precision: {val_precision}\")\n",
    "\n",
    "# Optional: Print more details for debugging\n",
    "#print(\"Validation labels:\", val_labels[:10])\n",
    "#print(\"Validation predictions:\", val_predictions[:10])\n",
    "\n",
    "test_images_2dpca = two_d_pca.transform(test_images)\n",
    "test_predictions = knn.predict(test_images_2dpca)\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_precision = precision_score(test_labels, test_predictions, average='macro',zero_division=1)\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c10aacff",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rf_classifier \u001b[38;5;241m=\u001b[39m \u001b[43mRandomForestClassifier\u001b[49m(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m      2\u001b[0m n_estimators \u001b[38;5;241m=\u001b[39m rf_classifier\u001b[38;5;241m.\u001b[39mn_estimators\n\u001b[1;32m      4\u001b[0m rf_classifier\u001b[38;5;241m.\u001b[39mfit(train_images_2dpca, train_labels)   \n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=100)\n",
    "n_estimators = rf_classifier.n_estimators\n",
    "\n",
    "rf_classifier.fit(train_images_2dpca, train_labels)   \n",
    "\n",
    "batch_size = 10  # Adjust as needed\n",
    "progress_bar = tqdm(total=n_estimators, desc=\"Training Random Forest\", position=0, leave=True)\n",
    "\n",
    "for i in range(0, n_estimators, batch_size):\n",
    "    # Ensure all samples in the batch are used for training\n",
    "    end_idx = min(i + batch_size, len(train_labels))\n",
    "    rf_classifier.fit(train_images_2dpca[i:end_idx], train_labels[i:end_idx])\n",
    "    progress_bar.update(end_idx - i)\n",
    "\n",
    "# Close tqdm progress bar after training completes\n",
    "progress_bar.close()\n",
    "\n",
    "val_predictions = rf_classifier.predict(val_images_2dpca)\n",
    "accuracy = accuracy_score(val_labels, val_predictions)\n",
    "    \n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "print(f\"Validation Precision: {val_precision}\")\n",
    "\n",
    "test_images_2dpca = two_d_pca.transform(test_images)\n",
    "test_predictions = rf_classifier.predict(test_images_2dpca)\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_precision = precision_score(test_labels, test_predictions, average='macro',zero_division=1)\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba9ea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2921c54e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
